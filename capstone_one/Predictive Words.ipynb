{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('kickstarter_analysis.pkl')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['category_core'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 10)\n",
    "X = vectorizer.fit_transform(df['blurb'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "classes = clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.eye(X.shape[1])\n",
    "probs = clf.predict_log_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art :\n",
      "sculpture | 0.93\n",
      "mural | 0.91\n",
      "installation | 0.83\n",
      "sculptures | 0.83\n",
      "painting | 0.83\n",
      "comics :\n",
      "webcomic | 0.87\n",
      "comic | 0.78\n",
      "comics | 0.72\n",
      "graphic | 0.63\n",
      "manga | 0.58\n",
      "crafts :\n",
      "candles | 0.92\n",
      "soaps | 0.79\n",
      "pens | 0.76\n",
      "candle | 0.74\n",
      "scented | 0.74\n",
      "dance :\n",
      "choreographers | 0.77\n",
      "ballet | 0.71\n",
      "dance | 0.66\n",
      "choreographer | 0.65\n",
      "choreography | 0.63\n",
      "design :\n",
      "font | 0.61\n",
      "titanium | 0.60\n",
      "edc | 0.58\n",
      "poster | 0.54\n",
      "logos | 0.53\n",
      "fashion :\n",
      "footwear | 0.87\n",
      "sandals | 0.79\n",
      "clothing | 0.78\n",
      "shoes | 0.78\n",
      "apparel | 0.77\n",
      "film & video :\n",
      "webseries | 0.93\n",
      "cortometraje | 0.91\n",
      "film | 0.87\n",
      "mockumentary | 0.86\n",
      "animated | 0.84\n",
      "food :\n",
      "gourmet | 0.93\n",
      "bakery | 0.92\n",
      "sauces | 0.92\n",
      "sauce | 0.89\n",
      "brewery | 0.89\n",
      "games :\n",
      "platformer | 0.90\n",
      "uspcc | 0.90\n",
      "rpg | 0.88\n",
      "28mm | 0.88\n",
      "strategy | 0.86\n",
      "journalism :\n",
      "journalism | 0.66\n",
      "news | 0.50\n",
      "journalists | 0.45\n",
      "reporting | 0.41\n",
      "coverage | 0.39\n",
      "music :\n",
      "ep | 0.97\n",
      "album | 0.97\n",
      "cd | 0.94\n",
      "lp | 0.92\n",
      "recording | 0.92\n",
      "photography :\n",
      "photobook | 0.87\n",
      "nudes | 0.77\n",
      "photographing | 0.73\n",
      "photographic | 0.71\n",
      "photography | 0.66\n",
      "publishing :\n",
      "poems | 0.82\n",
      "chapbook | 0.79\n",
      "literary | 0.76\n",
      "rhyming | 0.74\n",
      "essays | 0.74\n",
      "technology :\n",
      "arduino | 0.97\n",
      "raspberry | 0.91\n",
      "wireless | 0.89\n",
      "bluetooth | 0.89\n",
      "pi | 0.88\n",
      "theater :\n",
      "fringe | 0.74\n",
      "edinburgh | 0.69\n",
      "theatre | 0.68\n",
      "playwrights | 0.59\n",
      "teatro | 0.58\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(classes):\n",
    "    prob = probs[:,i]\n",
    "    ind = np.argsort(prob)[::-1]\n",
    "    \n",
    "    good_words = words[ind[:5]]\n",
    "    \n",
    "    good_prob = prob[ind[:5]]\n",
    "    \n",
    "    #print(\"Associated words\\t     P({} | word)\".format(c))\n",
    "    #for w, p in zip(good_words, good_prob):\n",
    "    #    print(\"{:>35}\".format(w), \"{:.2f}\".format(np.exp(p)))\n",
    "        \n",
    "    print(c,\":\")\n",
    "    for w, p in zip(good_words, good_prob):\n",
    "        print(\"{} | {:.2f}\".format(w, np.exp(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, most of the categories and their top 5 words make sense. They pretty much describe the category that tehy're in (i.e. the probability of art given that the word is 'sculpture' is 93%). It's surprising to see that not all categories have at least a few strongly predictive words (i.e. words giving probablity > 90%). The category \"dance\"'s most predictive word is \"choreographers\" at 77% and \"design\"s most preditive word is \"font\" at 61%.  \n",
    "\n",
    "Additionally, there are words that don't seem to make much sense such as \"edc\" predicting the \"design\" category and \"28mm\" predicting \"games\".   \n",
    "\n",
    "Since Kickstarters are international, there are also some words that are non-english being a big predictor of the category such as \"teatro\" for theater and \"cortometraje\"(short film) for film & video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy = df['failed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 10)\n",
    "fX = vectorizer.fit_transform(df['blurb'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(fX, fy)\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "classes = clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed words\t     P(1 | word)\n",
      "               tengo 0.95\n",
      "           ecommerce 0.95\n",
      "         contractors 0.94\n",
      "         videography 0.94\n",
      "               tarts 0.94\n",
      "             webpage 0.94\n",
      "              bijoux 0.94\n",
      "             pallets 0.93\n",
      "            toppings 0.93\n",
      "                buen 0.93\n",
      "Successful words\t     P(1 | word)\n",
      "             badgirl 0.04\n",
      "                32mm 0.04\n",
      "       choreographic 0.04\n",
      "            calavera 0.03\n",
      "            wargames 0.03\n",
      "                  5e 0.03\n",
      "                28mm 0.02\n",
      "                 gbs 0.01\n",
      "            everette 0.01\n",
      "             hartsoe 0.01\n"
     ]
    }
   ],
   "source": [
    "x = np.eye(X.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:10]]\n",
    "bad_words = words[ind[-10:]]\n",
    "\n",
    "good_prob = probs[ind[:10]]\n",
    "bad_prob = probs[ind[-10:]]\n",
    "\n",
    "print(\"Failed words\\t     P(1 | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Successful words\\t     P(1 | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
